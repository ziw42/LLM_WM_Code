# LLM_WM_Code
The codes in papers of Large Language Model Watermark  

Paper List:  
https://github.com/hzy312/Awesome-LLM-Watermark  
  
Text Watermark:  
**A Watermark for Large Language Models (lm-watermarking):**  
https://github.com/jwkirchenbauer/lm-watermarking  
https://arxiv.org/abs/2301.10226  
**Robust Distortion-free Watermarks for Language Models (watermark):**  
https://github.com/jthickstun/watermark  
https://arxiv.org/abs/2307.15593  
**Watermarking LLMs with Weight Quantization (Quantize-Watermark):**  
https://github.com/Twilight92z/Quantize-Watermark  
https://arxiv.org/pdf/2310.11237  
**A Semantic Invariant Robust Watermark for Large Language Models ï¼ˆRobust_Watermark):**  
https://github.com/THU-BPM/Robust_Watermark  
https://arxiv.org/abs/2310.06356 (empty repo)  
**Towards Codable Text Watermarking for Large Language Models (codable-watermarking-for-llm):**  
https://github.com/lancopku/codable-watermarking-for-llm  
https://arxiv.org/abs/2307.15992  
**A Private Watermark for Large Language Models (private_watermark):**  
https://github.com/THU-BPM/private_watermark  
https://arxiv.org/abs/2307.16230  
**Provable Robust Watermarking for AI-Generated Text (Unigram-Watermark):**  
https://github.com/XuandongZhao/Unigram-Watermark  
https://arxiv.org/abs/2306.17439  
**Robust Multi-bit Natural Language Watermarking through Invariant Features (nlp-watermarking):**  
https://github.com/bangawayoo/nlp-watermarking  
https://arxiv.org/pdf/2305.01904  
**Are You Copying My Model? Protecting the Copyright of Large Language Models for EaaS via Backdoor Watermark (EmbMarker):**  
https://github.com/yjw1029/EmbMarker  
https://arxiv.org/abs/2305.10036  
**Watermarking Text Generated by Black-Box Language Models (Text_Watermark_Language_Models):**  
https://github.com/Kiode/Text_Watermark_Language_Models  
https://arxiv.org/abs/2305.08883  
**Protecting Language Generation Models via Invisible Watermarking (Ginsew):**  
https://github.com/XuandongZhao/Ginsew  
https://arxiv.org/abs/2302.03162  
**Distillation-Resistant Watermarking for Model Protection in NLP (DRW):**  
https://github.com/XuandongZhao/DRW  
https://arxiv.org/abs/2210.03312  
**CATER: Intellectual Property Protection on Text Generation APIs via Conditional Watermarks (cater_neurips):**  
https://github.com/xlhex/cater_neurips.git  
https://arxiv.org/abs/2209.08773  
  
Image Watermark:  
**Invisible Image Watermarks Are Provably Removable Using Generative AI (WatermarkAttacker):**  
https://github.com/XuandongZhao/WatermarkAttacker  
https://arxiv.org/abs/2306.01953  
**Tree-Ring Watermarks: Fingerprints for Diffusion Images that are Invisible and Robust (tree-ring-watermark):**  
https://github.com/YuxinWenRick/tree-ring-watermark  
https://arxiv.org/abs/2305.20030  
**Evading Watermark based Detection of AI-Generated Content (WEvade):**  
https://github.com/zhengyuan-jiang/WEvade  
https://arxiv.org/abs/2305.03807  
**The Stable Signature: Rooting Watermarks in Latent Diffusion Models (invisible-watermark):**  
https://github.com/ShieldMnt/invisible-watermark  
https://arxiv.org/abs/2303.15435 (used in this paper, but not their code)  

